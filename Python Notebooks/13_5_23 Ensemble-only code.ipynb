{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2447836",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the dataset\n",
    "df1 = pd.read_excel('bng2eng2/train/ConscientiousnessTrain.xlsx')\n",
    "df2 = pd.read_excel('bng2eng2/train/AgreeablenessTrain.xlsx')\n",
    "df3 = pd.read_excel('bng2eng2/train/NeuroticismTrain.xlsx')\n",
    "df4 = pd.read_excel('bng2eng2/train/ExtroversionTrain.xlsx')\n",
    "df5 = pd.read_excel('bng2eng2/train/OpennessTrain.xlsx')\n",
    "train_df = pd.concat([df1, df2, df3, df4, df5], ignore_index=True)\n",
    "train_df = train_df.drop(\"status\", axis='columns')\n",
    "train_df\n",
    "\n",
    "df6 = pd.read_excel('bng2eng2/test/ConscientiousnessTest.xlsx')\n",
    "df7 = pd.read_excel('bng2eng2/test/AgreeablenessTest.xlsx')\n",
    "df8 = pd.read_excel('bng2eng2/test/NeuroticismTest.xlsx')\n",
    "df9 = pd.read_excel('bng2eng2/test/ExtroversionTest.xlsx')\n",
    "df10 = pd.read_excel('bng2eng2/test/OpennessTest.xlsx')\n",
    "test_df = pd.concat([df6, df7, df8, df9, df10], ignore_index=True)\n",
    "test_df = test_df.drop(\"status\", axis='columns')\n",
    "test_df\n",
    "\n",
    "# Data preprocessing\n",
    "# Convert text to lowercase\n",
    "train_df['status_text'] = train_df['status_text'].apply(lambda x: x.lower())\n",
    "\n",
    "print(test_df['status_text'].dtype)\n",
    "\n",
    "test_df['status_text'] = test_df['status_text'].apply(lambda y: str(y).lower())\n",
    "test_df\n",
    "\n",
    "# Remove stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "train_df['status_text'] = train_df['status_text'].apply(lambda x: ' '.join([word for word in x.split() if word not in stop_words]))\n",
    "test_df['status_text'] = test_df['status_text'].apply(lambda x: ' '.join([word for word in x.split() if word not in stop_words]))\n",
    "train_df\n",
    "\n",
    "# Tokenization\n",
    "train_df['status_text'] = train_df['status_text'].apply(lambda x: word_tokenize(x))\n",
    "test_df['status_text'] = test_df['status_text'].apply(lambda x: word_tokenize(x))\n",
    "train_df\n",
    "\n",
    "# # Stemming\n",
    "# stemmer = PorterStemmer()\n",
    "# train_df['status_text'] = train_df['status_text'].apply(lambda x: [stemmer.stem(word) for word in x])\n",
    "# test_df['status_text'] = test_df['status_text'].apply(lambda x: [stemmer.stem(word) for word in x])\n",
    "\n",
    "# Lemmatization\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "train_df['status_text'] = train_df['status_text'].apply(lambda x: [lemmatizer.lemmatize(word) for word in x])\n",
    "test_df['status_text'] = test_df['status_text'].apply(lambda x: [lemmatizer.lemmatize(word) for word in x])\n",
    "\n",
    "test_df\n",
    "\n",
    "# Convert list of tokens back to text\n",
    "train_df['status_text'] = train_df['status_text'].apply(lambda x: ' '.join(x))\n",
    "test_df['status_text'] = test_df['status_text'].apply(lambda x: ' '.join(x))\n",
    "train_df\n",
    "\n",
    "# Feature extraction using bag-of-words model\n",
    "count_vectorizer = CountVectorizer()\n",
    "X_train_counts = count_vectorizer.fit_transform(train_df['status_text'])\n",
    "X_test_counts = count_vectorizer.transform(test_df['status_text'])\n",
    "\n",
    "# Feature extraction using TF-IDF vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(train_df['status_text'])\n",
    "X_test_tfidf = tfidf_vectorizer.transform(test_df['status_text'])\n",
    "\n",
    "# Build a Multinomial Naive Bayes model using bag-of-words features\n",
    "mnb_counts_model = MultinomialNB()\n",
    "mnb_counts_model.fit(X_train_counts, train_df['label'])\n",
    "\n",
    "# Evaluate the model on the testing set using bag-of-words features\n",
    "y_pred_counts = mnb_counts_model.predict(X_test_counts)\n",
    "\n",
    "accuracy_counts = accuracy_score(test_df['label'], y_pred_counts)\n",
    "\n",
    "print(\"Accuracy using bag-of-words features:\", accuracy_counts)\n",
    "\n",
    "# Build a Multinomial Naive Bayes model using TF-IDF features\n",
    "mnb_tfidf_model = MultinomialNB()\n",
    "mnb_tfidf_model.fit(X_train_tfidf, train_df['label'])\n",
    "\n",
    "# Evaluate the model on the testing set using TF-IDF features\n",
    "y_pred_tfidf = mnb_tfidf_model.predict(X_test_tfidf)\n",
    "accuracy_tfidf = accuracy_score(test_df['label'], y_pred_tfidf)\n",
    "print(\"Accuracy using TF-IDF features:\", accuracy_tfidf)\n",
    "\n",
    "# Build a logistic regression model using TF-IDF features\n",
    "logreg_model = LogisticRegression()\n",
    "logreg_model.fit(X_train_tfidf, train_df['label'])\n",
    "\n",
    "# Evaluate the model on the testing set using TF-IDF features\n",
    "y_pred_logreg = logreg_model.predict(X_test_tfidf)\n",
    "accuracy_logreg = accuracy_score(test_df['label'], y_pred_logreg)\n",
    "print(\"Accuracy using logistic regression and TF-IDF features:\", accuracy_logreg)\n",
    "\n",
    "\n",
    "# Preprocess the text input\n",
    "input_text = \"I have a solution for this problem\"\n",
    "input_text = input_text.lower()\n",
    "input_text = ' '.join([word for word in input_text.split() if word not in stop_words])\n",
    "input_text = word_tokenize(input_text)\n",
    "input_text = [stemmer.stem(word) for word in input_text]\n",
    "input_text = ' '.join(input_text)\n",
    "\n",
    "# Extract features from the preprocessed text input\n",
    "X_input = tfidf_vectorizer.transform([input_text])\n",
    "\n",
    "# Predict the label of the input text using the logistic regression model\n",
    "y_pred_input = logreg_model.predict(X_input)[0]\n",
    "\n",
    "# Print the predicted label\n",
    "print(\"Predicted label for input text:\", y_pred_input)\n",
    "\n",
    "logreg_model = LogisticRegression()\n",
    "logreg_model.fit(X_train_tfidf, train_df['label'])\n",
    "\n",
    "rf_model = RandomForestClassifier(n_estimators=100)\n",
    "rf_model.fit(X_train_tfidf, train_df['label'])\n",
    "\n",
    "# Ensemble the models\n",
    "ensemble_model = VotingClassifier(estimators=[('mnb_counts', mnb_counts_model), \n",
    "                                               ('mnb_tfidf', mnb_tfidf_model), \n",
    "                                               ('logreg', logreg_model), \n",
    "                                               ('rf', rf_model)], \n",
    "                                   voting='hard')\n",
    "\n",
    "ensemble_model.fit(X_train_tfidf, train_df['label'])\n",
    "\n",
    "# Evaluate the model on the testing set\n",
    "y_pred_ensemble = ensemble_model.predict(X_test_tfidf)\n",
    "accuracy_ensemble = accuracy_score(test_df['label'], y_pred_ensemble)\n",
    "print(\"Accuracy using ensemble of models:\", accuracy_ensemble)\n",
    "\n",
    "# Preprocess the text input\n",
    "inp_txt = \"I have a solution for this problem\"\n",
    "inp_txt = inp_txt.lower()\n",
    "inp_txt = ' '.join([word for word in inp_txt.split() if word not in stop_words])\n",
    "inp_txt = word_tokenize(inp_txt)\n",
    "inp_txt = [stemmer.stem(word) for word in inp_txt]\n",
    "inp_txt = ' '.join(inp_txt)\n",
    "\n",
    "# Extract features from the preprocessed text input\n",
    "X_inp = tfidf_vectorizer.transform([inp_txt])\n",
    "\n",
    "# Predict the label of the input text using the logistic regression model\n",
    "y_pred_inp = ensemble_model.predict(X_inp)[0]\n",
    "\n",
    "# Print the predicted label\n",
    "print(\"Predicted label for input text:\", y_pred_inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4bca072",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>status_id</th>\n",
       "      <th>status_text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>792</td>\n",
       "      <td>I will not eat sugar from today. I will use th...</td>\n",
       "      <td>Conscientiousness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>921</td>\n",
       "      <td>For now, let policymakers reserve the bandwidt...</td>\n",
       "      <td>Conscientiousness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>922</td>\n",
       "      <td>We can't do anything, our parents don't allow ...</td>\n",
       "      <td>Conscientiousness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>978</td>\n",
       "      <td>Today I feel that becoming a doctor is worthwh...</td>\n",
       "      <td>Conscientiousness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>595</td>\n",
       "      <td>There will be no gain by forcing, the governme...</td>\n",
       "      <td>Conscientiousness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2392</th>\n",
       "      <td>2464</td>\n",
       "      <td>We were always positive. Now what is the back ...</td>\n",
       "      <td>Openness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2393</th>\n",
       "      <td>2455</td>\n",
       "      <td>Brother if I say I am Gopalganj, and the polic...</td>\n",
       "      <td>Openness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2394</th>\n",
       "      <td>2629</td>\n",
       "      <td>I have been watching the man since 12 years</td>\n",
       "      <td>Openness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2395</th>\n",
       "      <td>2597</td>\n",
       "      <td>It is very easy to defeat a man, but it is ver...</td>\n",
       "      <td>Openness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2396</th>\n",
       "      <td>2451</td>\n",
       "      <td>I noticed some negative things and not.</td>\n",
       "      <td>Openness</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2397 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      status_id                                        status_text  \\\n",
       "0           792  I will not eat sugar from today. I will use th...   \n",
       "1           921  For now, let policymakers reserve the bandwidt...   \n",
       "2           922  We can't do anything, our parents don't allow ...   \n",
       "3           978  Today I feel that becoming a doctor is worthwh...   \n",
       "4           595  There will be no gain by forcing, the governme...   \n",
       "...         ...                                                ...   \n",
       "2392       2464  We were always positive. Now what is the back ...   \n",
       "2393       2455  Brother if I say I am Gopalganj, and the polic...   \n",
       "2394       2629        I have been watching the man since 12 years   \n",
       "2395       2597  It is very easy to defeat a man, but it is ver...   \n",
       "2396       2451            I noticed some negative things and not.   \n",
       "\n",
       "                  label  \n",
       "0     Conscientiousness  \n",
       "1     Conscientiousness  \n",
       "2     Conscientiousness  \n",
       "3     Conscientiousness  \n",
       "4     Conscientiousness  \n",
       "...                 ...  \n",
       "2392           Openness  \n",
       "2393           Openness  \n",
       "2394           Openness  \n",
       "2395           Openness  \n",
       "2396           Openness  \n",
       "\n",
       "[2397 rows x 3 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Precision, recall, accuracy, F1 score : Comparative Study + Tabular form"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71489a55",
   "metadata": {},
   "source": [
    "I have the python code that trains a few models and uses an ensemble to classify textual social media posts int one of the Big Five personality traits. But the accuracy of the ensemble is stuck at 35%. Data available to me is limited. Could you please inspect the code and tell me which of the above hyperparameter tunings I sholud apply. Help me by modifying my python code accordingly. \n",
    "\n",
    "The code:\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
